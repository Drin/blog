# Paper Review: Discretized Streams: Fault-Tolerant Streaming Computation at Scale

## Review

#### What's new
* processing model that allows parallel recovery
* processing model that supports many operators *and* high throughput
* a readable API
* use of RDDs to batch specified intervals of a stream

#### Summary
The authors describe a streaming system that uses spark to take computation (RDD transformations and actions) and batches incoming stream data into RDDs to provide a system that has the benefits of RDDs with a readable, simple API. RDDs are not new from this paper, but their use in computing over streams is likely new. By treating an input stream as discrete batches, stream processing is almost trivially handled by spark's batch processing framework.


#### Thoughts/Comments
1. While the technical contribution of this paper is the application of RDDs and spark to streams, I think the most valuable contribution is actually the API. Spark utilizes a set-based semantics which allows developers to think more naturally about the dataset, but also allows developers to chain methods as they'd like instead of the 2-stage model that MapReduce established.

2. I think many of the straggler and fault-tolerance management trivially follows from the RDD paper, so I wish the authors focused more on something else, such as optimizations for stream processing. The lineage cutoff is interesting, and I just feel like there are some design trade-offs being made that I think would be more valuable for papers such as this to discuss.
